{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unless request information withheld comply fer...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none collect personal information computer e m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elect location based search saved history stor...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subsidiary corporate affiliate including enfor...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>use service view content provided google autom...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13545</th>\n",
       "      <td>opt targeted advertising</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13546</th>\n",
       "      <td>web page computer visit using service clickstr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13547</th>\n",
       "      <td>jibjab message sent visiting adjusting email p...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13548</th>\n",
       "      <td>receive store certain type information wheneve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13549</th>\n",
       "      <td>update my account</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13549 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  class\n",
       "0      unless request information withheld comply fer...      5\n",
       "1      none collect personal information computer e m...      5\n",
       "2      elect location based search saved history stor...      6\n",
       "3      subsidiary corporate affiliate including enfor...      5\n",
       "4      use service view content provided google autom...      2\n",
       "...                                                  ...    ...\n",
       "13545                           opt targeted advertising      6\n",
       "13546  web page computer visit using service clickstr...      5\n",
       "13547  jibjab message sent visiting adjusting email p...      6\n",
       "13548  receive store certain type information wheneve...      2\n",
       "13549                                  update my account      7\n",
       "\n",
       "[13549 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('dataset/train_preprocessed.csv', encoding='utf-8')\n",
    "train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (13550, 10)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(train_data['class']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data['text'], Y, \n",
    "                                                    test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=4000, output_sequence_length=40)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(X_train).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('GloVe/glove.6B.50d.txt', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 3729 words (271 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 1: array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 2: array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 3: array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " 4: array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " 5: array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " 6: array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]),\n",
       " 7: array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " 8: array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       " 9: array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 94\n"
     ]
    }
   ],
   "source": [
    "categories_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    value = np.zeros((10,))\n",
    "    value[i] = 1.0\n",
    "    categories_dict[i] = value\n",
    "\n",
    "categories_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "X_test_transformed = vectorizer(np.array([[s] for s in X_test])).numpy()\n",
    "\n",
    "y_train_transformed = np.array(y_train)\n",
    "y_test_transformed = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9485, 40)\n",
      "(4065, 40)\n",
      "(9485, 10)\n",
      "(4065, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)\n",
    "print(X_test_transformed.shape)\n",
    "print(y_train_transformed.shape)\n",
    "print(y_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_transformed = {}\n",
    "\n",
    "for key, value in y_train.items():\n",
    "    y_train_transformed[key] = categories_dict[value]\n",
    "    \n",
    "y_train_transformed = pd.Series(data=y_train_transformed)\n",
    "y_train_transformed = np.array(y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 453,  526,   91,  942,  458, 2010,    3,    2,  408,  134,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), ...,\n",
       "       array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       "       array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 453,  526,   91, ...,    0,    0,    0],\n",
       "       [ 227,   85,    3, ...,  298,  178,  477],\n",
       "       [ 187,   32,  198, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 307,   63, 1580, ...,    0,    0,    0],\n",
       "       [  97,  417,  362, ...,    0,    0,    0],\n",
       "       [   7,    2,   38, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_transformed = {}\n",
    "\n",
    "for key, value in y_test.items():\n",
    "    y_test_transformed[key] = categories_dict[value]\n",
    "    \n",
    "y_test_transformed = pd.Series(data=y_test_transformed)\n",
    "y_test_transformed = np.array(y_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 50)          200100    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, None, 50)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100)               60400     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                3232      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 264,062\n",
      "Trainable params: 63,962\n",
      "Non-trainable params: 200,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.7142 - accuracy: 0.7632 - val_loss: 0.7012 - val_accuracy: 0.7697\n",
      "Epoch 2/20\n",
      "149/149 [==============================] - 6s 40ms/step - loss: 0.7010 - accuracy: 0.7665 - val_loss: 0.7057 - val_accuracy: 0.7747\n",
      "Epoch 3/20\n",
      "149/149 [==============================] - 6s 40ms/step - loss: 0.6936 - accuracy: 0.7691 - val_loss: 0.6893 - val_accuracy: 0.7764\n",
      "Epoch 4/20\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.6880 - accuracy: 0.7676 - val_loss: 0.6995 - val_accuracy: 0.7764\n",
      "Epoch 5/20\n",
      "149/149 [==============================] - 6s 41ms/step - loss: 0.6727 - accuracy: 0.7772 - val_loss: 0.7152 - val_accuracy: 0.7744\n",
      "Epoch 6/20\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.6710 - accuracy: 0.7759 - val_loss: 0.6987 - val_accuracy: 0.7756\n",
      "Epoch 7/20\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.6613 - accuracy: 0.7784 - val_loss: 0.6990 - val_accuracy: 0.7766\n",
      "Epoch 8/20\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.6637 - accuracy: 0.7746 - val_loss: 0.6954 - val_accuracy: 0.7729\n",
      "Epoch 9/20\n",
      "149/149 [==============================] - 7s 45ms/step - loss: 0.6424 - accuracy: 0.7862 - val_loss: 0.7300 - val_accuracy: 0.7658\n",
      "Epoch 10/20\n",
      "149/149 [==============================] - 7s 45ms/step - loss: 0.6467 - accuracy: 0.7824 - val_loss: 0.6891 - val_accuracy: 0.7788\n",
      "Epoch 11/20\n",
      "149/149 [==============================] - 7s 46ms/step - loss: 0.6345 - accuracy: 0.7866 - val_loss: 0.6989 - val_accuracy: 0.7779\n",
      "Epoch 12/20\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.6329 - accuracy: 0.7850 - val_loss: 0.6856 - val_accuracy: 0.7825\n",
      "Epoch 13/20\n",
      "149/149 [==============================] - 7s 45ms/step - loss: 0.6142 - accuracy: 0.7947 - val_loss: 0.6656 - val_accuracy: 0.7815\n",
      "Epoch 14/20\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.6143 - accuracy: 0.7918 - val_loss: 0.6809 - val_accuracy: 0.7788\n",
      "Epoch 15/20\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.6102 - accuracy: 0.7920 - val_loss: 0.6626 - val_accuracy: 0.7894\n",
      "Epoch 16/20\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.6100 - accuracy: 0.7956 - val_loss: 0.6613 - val_accuracy: 0.7882\n",
      "Epoch 17/20\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.6001 - accuracy: 0.8002 - val_loss: 0.6665 - val_accuracy: 0.7879\n",
      "Epoch 18/20\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.5980 - accuracy: 0.7903 - val_loss: 0.6700 - val_accuracy: 0.7838\n",
      "Epoch 19/20\n",
      "149/149 [==============================] - 6s 43ms/step - loss: 0.5987 - accuracy: 0.7978 - val_loss: 0.6770 - val_accuracy: 0.7781\n",
      "Epoch 20/20\n",
      "149/149 [==============================] - 7s 44ms/step - loss: 0.5770 - accuracy: 0.8059 - val_loss: 0.6716 - val_accuracy: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231bbc89fc0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_transformed, y_train_transformed, batch_size=64, epochs=20, \n",
    "          validation_data=(X_test_transformed, y_test_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None) <dtype: 'float32'>\n",
      "**\n",
      "(None, None, 10) <dtype: 'float32'>\n",
      "**\n",
      "embedding_1 (None, None) float32\n",
      "lstm_2 (None, None, 50) float32\n",
      "dropout_4 (None, None, 128) float32\n",
      "dense_4 (None, None, 128) float32\n",
      "dropout_5 (None, None, 32) float32\n",
      "dense_5 (None, None, 32) float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i.shape, i.dtype) for i in model.inputs]\n",
    "print(\"**\")\n",
    "[print(o.shape, o.dtype) for o in model.outputs]\n",
    "print(\"**\")\n",
    "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
