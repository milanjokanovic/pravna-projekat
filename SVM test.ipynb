{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('validation.csv',\n",
    "                       encoding='utf-8', names=['text', 'class'], skiprows =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sci-News.com does not knowingly collect or sol...</td>\n",
       "      <td>Privacy contact information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Submitting an Order When you submit an order ...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We use cookies to enhance the browsing and sho...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This privacy statement covers the site new.www...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Information Collection and Use Information Co...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We also require our credit card transaction pr...</td>\n",
       "      <td>Data Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This privacy statement covers the use of cook...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Any comments or materials sent to Caribou Coff...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Caribou keeps your cell phone number private a...</td>\n",
       "      <td>Data Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Clear Gifs can \"\"work with\"\" existing cookies ...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d. Except as specified herein, this policy als...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aggregate Information (non-personally identifi...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b. Cookies. (i) Hearst (or third party service...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>We DO NOT Share Personal Information with Thi...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>e. Location Information. We may, and may enabl...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>f. Third Parties. We may receive information f...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b. We may combine and use any and all informat...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4. Disclosure of Your Information a. In additi...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(viii) We need to protect our legal rights (fo...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>c. Third Party Partners. Some of our Covered S...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>d. Delivery of Advertising and Other Content. ...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Other information . Please note that AOL may u...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>We may share information with: Affiliates . Th...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Other parties in response to legal process or ...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Companies that Provide Services to AOL Compan...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Privacy Policy Last modified: June 30, 2015 ( ...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>There are many different ways you can use our ...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>We may use the name you provide for your Googl...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Our automated systems analyze your content (in...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>This statement explains our privacy policies a...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Terms of use By accessing or using a website ...</td>\n",
       "      <td>Policy Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>What We Collect We collect the information yo...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Links and Third-Party Content Our Sites may c...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>You must provide the statement \"\"Your Californ...</td>\n",
       "      <td>International and Specific Audiences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>How To Obtain A Copy Of Revised Notice. Kaleid...</td>\n",
       "      <td>Policy Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Family and Friends Involved In Your Care. If y...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Emergencies. Kaleida Health may use or disclos...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>To Avert A Serious And Imminent Threat To Heal...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Inmates And Correctional Institutions. If you ...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>An accounting of disclosures also does not inc...</td>\n",
       "      <td>Practice not covered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>To request more confidential communications, p...</td>\n",
       "      <td>Privacy contact information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>Privacy, Security, and Accessibility Policies</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>Unauthorized attempts to upload information or...</td>\n",
       "      <td>Practice not covered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>To get aggregate metrics on site usage to und...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>External Links USA.gov links to many websites...</td>\n",
       "      <td>Practice not covered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>E-mail Information Please do not send us sens...</td>\n",
       "      <td>Data Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>External links are intended to support NARA's ...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>We work hard to ensure the information provide...</td>\n",
       "      <td>Introductory/Generic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Collection of your Personal Information: We w...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Control of your Personal Information: Except ...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>ABITA.COM may send out periodic e-mails inform...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Security of your Personal Information: Abita ...</td>\n",
       "      <td>Data Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Unsubscribe Information Instructions to remov...</td>\n",
       "      <td>User Choice/Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Even without accepting cookies, you can access...</td>\n",
       "      <td>User Choice/Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>Customer Service Correspondence. We may collec...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>Other Emergencies. We may disclose personal in...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Company Sale. Information collected through ou...</td>\n",
       "      <td>Third Party Sharing/Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Aggregate Information. We collect Aggregate In...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>THE USE OF COOKIES Cookies are alphanumeric id...</td>\n",
       "      <td>First Party Collection/Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>By using the Site, you are accepting the pract...</td>\n",
       "      <td>Policy Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Sci-News.com does not knowingly collect or sol...   \n",
       "1     Submitting an Order When you submit an order ...   \n",
       "3    We use cookies to enhance the browsing and sho...   \n",
       "5    This privacy statement covers the site new.www...   \n",
       "6     Information Collection and Use Information Co...   \n",
       "8    We also require our credit card transaction pr...   \n",
       "9     This privacy statement covers the use of cook...   \n",
       "11   Any comments or materials sent to Caribou Coff...   \n",
       "12   Caribou keeps your cell phone number private a...   \n",
       "14   Clear Gifs can \"\"work with\"\" existing cookies ...   \n",
       "15   d. Except as specified herein, this policy als...   \n",
       "16   Aggregate Information (non-personally identifi...   \n",
       "17   b. Cookies. (i) Hearst (or third party service...   \n",
       "19    We DO NOT Share Personal Information with Thi...   \n",
       "20   e. Location Information. We may, and may enabl...   \n",
       "22   f. Third Parties. We may receive information f...   \n",
       "23   b. We may combine and use any and all informat...   \n",
       "24   4. Disclosure of Your Information a. In additi...   \n",
       "25   (viii) We need to protect our legal rights (fo...   \n",
       "26   c. Third Party Partners. Some of our Covered S...   \n",
       "27   d. Delivery of Advertising and Other Content. ...   \n",
       "28   Other information . Please note that AOL may u...   \n",
       "29   We may share information with: Affiliates . Th...   \n",
       "30   Other parties in response to legal process or ...   \n",
       "31    Companies that Provide Services to AOL Compan...   \n",
       "32   Privacy Policy Last modified: June 30, 2015 ( ...   \n",
       "33   There are many different ways you can use our ...   \n",
       "35   We may use the name you provide for your Googl...   \n",
       "37   Our automated systems analyze your content (in...   \n",
       "38   This statement explains our privacy policies a...   \n",
       "..                                                 ...   \n",
       "613   Terms of use By accessing or using a website ...   \n",
       "614   What We Collect We collect the information yo...   \n",
       "617   Links and Third-Party Content Our Sites may c...   \n",
       "618  You must provide the statement \"\"Your Californ...   \n",
       "619  How To Obtain A Copy Of Revised Notice. Kaleid...   \n",
       "620  Family and Friends Involved In Your Care. If y...   \n",
       "621  Emergencies. Kaleida Health may use or disclos...   \n",
       "623  To Avert A Serious And Imminent Threat To Heal...   \n",
       "625  Inmates And Correctional Institutions. If you ...   \n",
       "626  An accounting of disclosures also does not inc...   \n",
       "627  To request more confidential communications, p...   \n",
       "628     Privacy, Security, and Accessibility Policies    \n",
       "629  Unauthorized attempts to upload information or...   \n",
       "630   To get aggregate metrics on site usage to und...   \n",
       "631   External Links USA.gov links to many websites...   \n",
       "632   E-mail Information Please do not send us sens...   \n",
       "633  External links are intended to support NARA's ...   \n",
       "634  We work hard to ensure the information provide...   \n",
       "635   Collection of your Personal Information: We w...   \n",
       "636   Control of your Personal Information: Except ...   \n",
       "637  ABITA.COM may send out periodic e-mails inform...   \n",
       "638   Security of your Personal Information: Abita ...   \n",
       "639   Unsubscribe Information Instructions to remov...   \n",
       "640  Even without accepting cookies, you can access...   \n",
       "641  Customer Service Correspondence. We may collec...   \n",
       "642  Other Emergencies. We may disclose personal in...   \n",
       "643  Company Sale. Information collected through ou...   \n",
       "644  Aggregate Information. We collect Aggregate In...   \n",
       "645  THE USE OF COOKIES Cookies are alphanumeric id...   \n",
       "646  By using the Site, you are accepting the pract...   \n",
       "\n",
       "                                    class  \n",
       "0             Privacy contact information  \n",
       "1              First Party Collection/Use  \n",
       "3              First Party Collection/Use  \n",
       "5                    Introductory/Generic  \n",
       "6              First Party Collection/Use  \n",
       "8                           Data Security  \n",
       "9          Third Party Sharing/Collection  \n",
       "11             First Party Collection/Use  \n",
       "12                          Data Security  \n",
       "14                   Introductory/Generic  \n",
       "15         Third Party Sharing/Collection  \n",
       "16         Third Party Sharing/Collection  \n",
       "17             First Party Collection/Use  \n",
       "19         Third Party Sharing/Collection  \n",
       "20             First Party Collection/Use  \n",
       "22             First Party Collection/Use  \n",
       "23             First Party Collection/Use  \n",
       "24         Third Party Sharing/Collection  \n",
       "25         Third Party Sharing/Collection  \n",
       "26         Third Party Sharing/Collection  \n",
       "27         Third Party Sharing/Collection  \n",
       "28             First Party Collection/Use  \n",
       "29         Third Party Sharing/Collection  \n",
       "30         Third Party Sharing/Collection  \n",
       "31         Third Party Sharing/Collection  \n",
       "32                   Introductory/Generic  \n",
       "33             First Party Collection/Use  \n",
       "35             First Party Collection/Use  \n",
       "37             First Party Collection/Use  \n",
       "38                   Introductory/Generic  \n",
       "..                                    ...  \n",
       "613                         Policy Change  \n",
       "614            First Party Collection/Use  \n",
       "617        Third Party Sharing/Collection  \n",
       "618  International and Specific Audiences  \n",
       "619                         Policy Change  \n",
       "620        Third Party Sharing/Collection  \n",
       "621            First Party Collection/Use  \n",
       "623            First Party Collection/Use  \n",
       "625        Third Party Sharing/Collection  \n",
       "626                  Practice not covered  \n",
       "627           Privacy contact information  \n",
       "628                  Introductory/Generic  \n",
       "629                  Practice not covered  \n",
       "630            First Party Collection/Use  \n",
       "631                  Practice not covered  \n",
       "632                         Data Security  \n",
       "633                  Introductory/Generic  \n",
       "634                  Introductory/Generic  \n",
       "635            First Party Collection/Use  \n",
       "636        Third Party Sharing/Collection  \n",
       "637            First Party Collection/Use  \n",
       "638                         Data Security  \n",
       "639                   User Choice/Control  \n",
       "640                   User Choice/Control  \n",
       "641            First Party Collection/Use  \n",
       "642        Third Party Sharing/Collection  \n",
       "643        Third Party Sharing/Collection  \n",
       "644            First Party Collection/Use  \n",
       "645            First Party Collection/Use  \n",
       "646                         Policy Change  \n",
       "\n",
       "[550 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(subset =\"text\",\n",
    "                     keep = 'first', inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'First Party Collection/Use': 0,\n",
    "         'Third Party Sharing/Collection': 1,\n",
    "         'User Choice/Control': 2,\n",
    "         'Privacy contact information': 3,\n",
    "         'Introductory/Generic': 4,\n",
    "         'Practice not covered': 5,\n",
    "         'Data Security': 6,\n",
    "         'User Access, Edit and Deletion': 7,\n",
    "         'Policy Change': 8,\n",
    "         'Do Not Track': 9,\n",
    "         'International and Specific Audiences': 10,\n",
    "         'Data Retention': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_classes_with_numbers(text):\n",
    "    return dict[text]\n",
    "\n",
    "data['class'] =data['class'].apply(replace_classes_with_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Milan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      sci-news.com knowingly collect solicit persona...\n",
      "1      submitting order submit order ask name, email ...\n",
      "3      use cookies enhance browsing shopping experien...\n",
      "5      privacy statement covers site new.www.redorbit...\n",
      "6      information collection use information collect...\n",
      "8      also require credit card transaction processor...\n",
      "9      privacy statement covers use cookies redorbit,...\n",
      "11     comments materials sent caribou coffee site, i...\n",
      "12     caribou keeps cell phone number private times....\n",
      "14     clear gifs \"\"work with\"\" existing cookies comp...\n",
      "15     d. except specified herein, policy also apply ...\n",
      "16     aggregate information (non-personally identifi...\n",
      "17     b. cookies. (i) hearst (or third party service...\n",
      "19     share personal information third parties third...\n",
      "20     e. location information. may, enable advertise...\n",
      "22     f. third parties. receive information third pa...\n",
      "23     b. combine use information collect either onli...\n",
      "24     4. disclosure information a. addition disclosu...\n",
      "25     (viii) need protect legal rights (for example,...\n",
      "26     c. third party partners. covered sites time ti...\n",
      "27     d. delivery advertising content. (i) addition ...\n",
      "28     information . please note aol use information ...\n",
      "29     share information with: affiliates . informati...\n",
      "30     parties response legal process necessary prote...\n",
      "31     companies provide services aol companies provi...\n",
      "32     privacy policy last modified: june 30, 2015 ( ...\n",
      "33     many different ways use services - search shar...\n",
      "35     use name provide google profile across service...\n",
      "37     automated systems analyze content (including e...\n",
      "38     statement explains privacy policies procedures...\n",
      "                             ...                        \n",
      "613    terms use accessing using website operated new...\n",
      "614    collect collect information affirmatively choo...\n",
      "617    links third-party content sites contain links ...\n",
      "618    must provide statement \"\"your california priva...\n",
      "619    obtain copy revised notice. kaleida health cha...\n",
      "620    family friends involved care. object, kaleida ...\n",
      "621    emergencies. kaleida health use disclose healt...\n",
      "623    avert serious imminent threat health safety. k...\n",
      "625    inmates correctional institutions. inmate deta...\n",
      "626    accounting disclosures also include informatio...\n",
      "627    request confidential communications, please wr...\n",
      "628            privacy, security, accessibility policies\n",
      "629    unauthorized attempts upload information chang...\n",
      "630    get aggregate metrics site usage understand pe...\n",
      "631    external links usa.gov links many websites cre...\n",
      "632    e-mail information please send us sensitive in...\n",
      "633    external links intended support nara's mission...\n",
      "634    work hard ensure information provided accurate...\n",
      "635    collection personal information: ask need info...\n",
      "636    control personal information: except otherwise...\n",
      "637    abita.com send periodic e-mails informing issu...\n",
      "638    security personal information: abita committed...\n",
      "639    unsubscribe information instructions remove em...\n",
      "640    even without accepting cookies, access feature...\n",
      "641    customer service correspondence. collect infor...\n",
      "642    emergencies. disclose personal information bel...\n",
      "643    company sale. information collected website co...\n",
      "644    aggregate information. collect aggregate infor...\n",
      "645    use cookies cookies alphanumeric identifiers c...\n",
      "646    using site, accepting practices described priv...\n",
      "Name: text, Length: 550, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('may') #???\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "print(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Milan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "\n",
    "data['text'] = data['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('preprocessed_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from here SVM test\n",
    "train_data = pd.read_csv('preprocessed.csv',\n",
    "                       encoding='utf-8', names=['text', 'class'], skiprows =1)\n",
    "validation = pd.read_csv('preprocessed_validation.csv',\n",
    "                       encoding='utf-8', names=['text', 'class'], skiprows =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenized = [[w for w in sentence.split(\" \") if w != \"\"] for sentence in train_data['text']]\n",
    "x_validation_tokenized = [[w for w in sentence.split(\" \") if w != \"\"] for sentence in validation['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process took 1.07 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = gensim.models.Word2Vec(x_tokenized,\n",
    "                 vector_size=100\n",
    "                )\n",
    "validation_model = gensim.models.Word2Vec(x_tokenized,\n",
    "                 vector_size=100\n",
    "                )\n",
    "\n",
    "end = round(time.time()-start,2)\n",
    "print(\"This process took\",end,\"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('call', 0.9989032745361328),\n",
       " ('day', 0.9984313249588013),\n",
       " ('opportunity', 0.9983790516853333),\n",
       " ('stop', 0.9982364177703857),\n",
       " ('account,', 0.9982260465621948),\n",
       " ('latin', 0.9981867671012878),\n",
       " ('opted', 0.9981570243835449),\n",
       " ('exchange', 0.9980195164680481),\n",
       " ('e-mail,', 0.9979535937309265),\n",
       " ('sending', 0.9978770017623901)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequencer():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 all_words,\n",
    "                 max_words,\n",
    "                 seq_len,\n",
    "                 embedding_matrix\n",
    "                ):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.embed_matrix = embedding_matrix\n",
    "        \"\"\"\n",
    "        temp_vocab = Vocab which has all the unique words\n",
    "        self.vocab = Our last vocab which has only most used N words.\n",
    "    \n",
    "        \"\"\"\n",
    "        temp_vocab = list(set(all_words))\n",
    "        self.vocab = []\n",
    "        self.word_cnts = {}\n",
    "        \"\"\"\n",
    "        Now we'll create a hash map (dict) which includes words and their occurencies\n",
    "        \"\"\"\n",
    "        for word in temp_vocab:\n",
    "            # 0 does not have a meaning, you can add the word to the list\n",
    "            # or something different.\n",
    "            count = len([0 for w in all_words if w == word])\n",
    "            self.word_cnts[word] = count\n",
    "            counts = list(self.word_cnts.values())\n",
    "            indexes = list(range(len(counts)))\n",
    "        \n",
    "        # Now we'll sort counts and while sorting them also will sort indexes.\n",
    "        # We'll use those indexes to find most used N word.\n",
    "        cnt = 0\n",
    "        while cnt + 1 != len(counts):\n",
    "            cnt = 0\n",
    "            for i in range(len(counts)-1):\n",
    "                if counts[i] < counts[i+1]:\n",
    "                    counts[i+1],counts[i] = counts[i],counts[i+1]\n",
    "                    indexes[i],indexes[i+1] = indexes[i+1],indexes[i]\n",
    "                else:\n",
    "                    cnt += 1\n",
    "        \n",
    "        for ind in indexes[:max_words]:\n",
    "            self.vocab.append(temp_vocab[ind])\n",
    "                    \n",
    "    def textToVector(self,text):\n",
    "        # First we need to split the text into its tokens and learn the length\n",
    "        # If length is shorter than the max len we'll add some spaces (100D vectors which has only zero values)\n",
    "        # If it's longer than the max len we'll trim from the end.\n",
    "        tokens = text.split()\n",
    "        len_v = len(tokens)-1 if len(tokens) < self.seq_len else self.seq_len-1\n",
    "        vec = []\n",
    "        for tok in tokens[:len_v]:\n",
    "            try:\n",
    "                vec.append(self.embed_matrix[tok])\n",
    "            except Exception as E:\n",
    "                pass\n",
    "        \n",
    "        last_pieces = self.seq_len - len(vec)\n",
    "        for i in range(last_pieces):\n",
    "            vec.append(np.zeros(100,))\n",
    "        \n",
    "        return np.asarray(vec).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencer = Sequencer(all_words = [token for seq in x_tokenized for token in seq],\n",
    "              max_words = 1200,\n",
    "              seq_len = 15,\n",
    "              embedding_matrix = model.wv\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec = sequencer.textToVector(validation['text'][0])\n",
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2639, 1500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vecs = np.asarray([sequencer.textToVector(\" \".join(seq)) for seq in x_tokenized])\n",
    "x_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 1500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation_vecs = np.asarray([sequencer.textToVector(\" \".join(seq)) for seq in x_validation_tokenized])\n",
    "x_validation_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of variance ratios:  0.9102913023207337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_model = PCA(n_components=50)\n",
    "pca_model.fit(x_vecs)\n",
    "print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2639, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comps = pca_model.transform(x_vecs)\n",
    "x_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation_comps = pca_model.transform(x_validation_vecs)\n",
    "x_validation_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier has fitted, this process took 0.61 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_comps, train_data['class'])\n",
    "\n",
    "end = time.time()\n",
    "process = round(end-start,2)\n",
    "print(\"Support Vector Machine Classifier has fitted, this process took {} seconds\".format(process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49272727272727274"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.score(x_validation_comps, validation['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.79      0.61       175\n",
      "           1       0.48      0.57      0.53       127\n",
      "           2       0.57      0.11      0.18        38\n",
      "           3       0.53      0.40      0.46        20\n",
      "           4       0.45      0.53      0.49        60\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.50      0.04      0.08        24\n",
      "           7       0.00      0.00      0.00        22\n",
      "           8       0.80      0.33      0.47        24\n",
      "           9       0.00      0.00      0.00         4\n",
      "          10       0.35      0.21      0.26        33\n",
      "          11       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.49       550\n",
      "   macro avg       0.35      0.25      0.26       550\n",
      "weighted avg       0.46      0.49      0.44       550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "prediction = svm_classifier.predict(x_validation_comps)\n",
    "result = classification_report(validation['class'], prediction)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4c1f0860e70c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tokenized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_validation_tokenized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    766\u001b[0m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m                                 force_all_finite='allow-nan', reset=first_call)\n\u001b[0m\u001b[0;32m    769\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32md:\\projects\\python projects\\venv 3.6.8\\venv\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = make_pipeline(StandardScaler(with_mean=False), SVC(gamma='auto', kernel='sigmoid', C=2.5))\n",
    "clf.fit(x_tokenized, train_data['class'])\n",
    "y_pred = clf.predict(x_validation_tokenized)\n",
    "\n",
    "acc = accuracy_score(validation['class'], y_pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
